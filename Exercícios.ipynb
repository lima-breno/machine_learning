{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lima-breno/machine_learning/blob/main/Exerc%C3%ADcios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXh6sG7NJ6TI"
      },
      "source": [
        "# Aula 01 - Exercício 01\n",
        "**Autor**: Renan Santos Mendes\n",
        "\n",
        "**Email**: renansantosmendes@gmail.com\n",
        "\n",
        "**Descrição**: Este notebook apresenta um exemplo de modelos de aprendizado de máquina para o problema de classificação\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieMy0q9qJ6TP"
      },
      "source": [
        "### Instalando os pacotes externos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IWpOn56J6TP",
        "outputId": "ff23e9cd-4d26-4e77-ea6a-d546fc2a40da"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mA execução de células com 'Python 3.7.7' requer o pacote ipykernel.\n",
            "\u001b[1;31mExecute o seguinte comando para instalar \"ipykernel\" no ambiente do Python. \n",
            "\u001b[1;31mComando: \"\"c:/Users/Breno Lima/AppData/Local/Programs/Python/Python37/python.exe\" -m pip install ipykernel -U --user --force-reinstall\""
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install -U mlflow --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tANC3vR4wCc4"
      },
      "source": [
        "### Clonando o repositório"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGwKUVDD1mh2"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/renansantosmendes/lectures-datasets-2023.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1uJ3eK9wHeC"
      },
      "source": [
        "### Importando os pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdlLKafu1DTr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj5rmSygrUqc"
      },
      "outputs": [],
      "source": [
        "667/13000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DYd_-KDJ6TV"
      },
      "source": [
        "### Lendo o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAyEyuIz14F7"
      },
      "outputs": [],
      "source": [
        "FILE_PATH = 'lectures-datasets-2023'\n",
        "FILE_NAME = 'diabetes.csv'\n",
        "RANDOM_STATE = 42\n",
        "data = pd.read_csv(os.path.join(FILE_PATH, FILE_NAME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79NvuJzJ_zJs"
      },
      "outputs": [],
      "source": [
        "data['Outcome'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED07efvYJ6TW"
      },
      "source": [
        "### Visualizando os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0GSCUJ82UkN"
      },
      "outputs": [],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1i-QdAT2gj8"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imjom11mJ6TY"
      },
      "source": [
        "## Fazendo a transformação e separação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQzSguhVzTdt"
      },
      "outputs": [],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7uQEnAD270_"
      },
      "outputs": [],
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTbMQfeWxR4-"
      },
      "source": [
        "#### Transformando os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiPI9td0J6TY"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler() #calcula a media e desvio padrao para cada uma das colunas\n",
        "X = scaler.fit_transform(X) #Ajusta e transforma para cada coluna da scaler -> Foi feita alteração apenas o X. Pois ele é o padrao (dado entrada)\n",
        "                            #que quero aprender e relacionar com y. alteração =~ escala, pesos iguais pra todos..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YYHEh53xVGt"
      },
      "source": [
        "#### Fazendo a separação em dados de treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIApQiTIJ6TY",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, #esse argumento vai quebrar os dados de acordo com a ordem que ele está no DF. Ele faz a quebra em tuplas.\n",
        "                                                    y,\n",
        "                                                    test_size = 0.25, #25% dos dados vao para o teste! Posso usar o 'train_size' = 0.75\n",
        "                                                    random_state=RANDOM_STATE) #aleatoriza a seleção do dado para poder treinar. Garante que na mesma semente ele vai rodar o mesmo resultado\n",
        "# o embaralhamento é feito com tudo ao mesmo tempo, x e y.Por isso dá boa.\n",
        "print(f\"Train data shape of X = {X_train.shape} and Y = {y_train.shape}\")\n",
        "print(f\"Test data shape of X = {X_test.shape} and Y = {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJppMI53qVCW"
      },
      "outputs": [],
      "source": [
        "#OBS: Etapas da criação do modelo:\n",
        "# 01: criar o modelo(aqui eu preciso definir o modelo que quero: linear, linear multiplo, logistico, etc.. é teste até identificar qual o melhor modelo!)\n",
        "log_reg = LogisticRegression() #criando modelo de regressao logistica e atribuindo alog_reg\n",
        "# 02: treinar o modelo\n",
        "log_reg.fit(X = X_train ,  #dados de entrada - X em MAIUSCULO\n",
        "            y = y_train) #dados de saída - y em minusculo (qm eu quero prever)\n",
        "##PRonto, modelo está treinado!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbw06zJMqVCW"
      },
      "outputs": [],
      "source": [
        "# como descobrir o \"quão bom \" o modelo treinado está (métrica: acurácia - ela só identifica quem/quanto o modelo está acertando, CUIDADO!):\n",
        " #rodando em cima dos dados de teste para poder prever\n",
        "  # identificando (neste dataset) quantas pessoas tem diabetes e quantas nao tem\n",
        "\n",
        "#primeiro vejo uma amostra que eu saiba e peço pra ele prever (ele deve ser o mesmo que os dados que separei pro test!)\n",
        "y_pred = log_reg.predict(X = X_test)\n",
        "\n",
        "#OBS: se n for ajustada a semente, pode ser que o resltado dê diferente! (random_state= Random_State)\n",
        "\n",
        "#Para verificar se o teste deu boa (teste de acurácia) -> resultado em percentual - depois multiplicar por 100\n",
        "accuracy_score(y_true = y_test, #aqui devo considerar qual o X_test (valores de entrada) e o y_test (valor de saida)\n",
        "               y_pred = y_pred )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYJrL3A7xau2"
      },
      "source": [
        "#### Treinando nosso primeiro modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWFtsioY3OSi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "import mlflow\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QV2yfnExeLZ"
      },
      "source": [
        "#### Fazendo mais um treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql8MLNUz6o49"
      },
      "outputs": [],
      "source": [
        "###OBSERVACAO\n",
        "#autolog -> faz o log automatico do modelo\n",
        "    # todo e qualquer treino que eu fizer vai ser feito o log/artefato(modelo, ambiente..)\n",
        "mlflow.sklearn.autolog(log_post_training_metrics=True)\n",
        "\n",
        "#esse log vai estar no arquivo (canto esquerdo, pasta chamada \"mlruns\", dentro da pasta vai ter uma pasta 0, dentro desta pasta terá o ID do autologging.\n",
        "# qd vc entra na pasta da ID, vc vai ter o arquivos artefacts, params e metas.)\n",
        "    #CUIDADOS: parametro é tudo aquilo que o modelo aprende. no mlflow a pasta params não se refere aos parametros. Params no mlflow é a configuração que vc usou.\n",
        "       # ele salva um arquivo para cada uma da configuração utilizada\n",
        "       #pasta metricas que ele pega: acuracia, precisão, recall, f1, ROC,\n",
        "        # qd vc abre o arqu, a primeira coluna é a timestamp, depois o valor da métrica e por ultimo o indice (para qd tiver mais metricas)\n",
        "\n",
        "    #pasta artifacts: pega varios graficos, na pasta modelo tem o arquivo \"model.pkl\" é o modelo que iremos utilizar! que salva tudo (dataset, modelo, etc.)\n",
        "        # podemos utlizar esse arquivo para a produção sem problema algum\n",
        "            # no arquivo requirements.txt tem todas as bibliotecas e versões utilizadas.\n",
        "            # no arquivo python_env tenho as infos do ambiente python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thxBCu7vqVCY"
      },
      "source": [
        "PRevisão para um exemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_y8jlfLo9E62"
      },
      "outputs": [],
      "source": [
        "me = np.array([0, 30, 72, 60, 0, 20, 0.500, 0]).reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOmxmBcCqVCZ",
        "outputId": "bc4d68e7-83e0-4f1d-a5a5-62b8d9e11277"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mA execução de células com 'Python 3.7.7' requer o pacote ipykernel.\n",
            "\u001b[1;31mExecute o seguinte comando para instalar \"ipykernel\" no ambiente do Python. \n",
            "\u001b[1;31mComando: \"\"c:/Users/Breno Lima/AppData/Local/Programs/Python/Python37/python.exe\" -m pip install ipykernel -U --user --force-reinstall\""
          ]
        }
      ],
      "source": [
        "#Normalizando a array\n",
        "me_scaled = scaler.transform(me)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVefrWNF87h9"
      },
      "outputs": [],
      "source": [
        "log_reg.predict(scaler.transform(me))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wDLVXXiqVCZ"
      },
      "source": [
        "Para salvar o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwjhHhYkwfBf"
      },
      "outputs": [],
      "source": [
        "#plataforma dagshub.com -> plataforma para armazenar experimentos de data science (estilo github). Ela armazena códigos tb.\n",
        "# crio o notbook por lá e ele vai indicar os comandos para colocar no colab e linkar colab com dagshub.\n",
        "#ao rodar o experimento no colab, o dags já salva direto, aí vc consegue ver por lá os parametro"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}